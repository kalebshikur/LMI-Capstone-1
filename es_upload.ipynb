{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Splitting & ElasticSearch Uploads\n",
    "## LMI Capstone Team\n",
    "## Summer Chambers | Steve Morris | Kaleb Shikur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Rule Splitting, Uploading to ES\n",
    "'''\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "# from requests_aws4auth import AWS4Auth\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests #gets urls\n",
    "# from aws_requests_auth.boto_utils import BotoAWSRequestsAuth\n",
    "\n",
    "host = 'https://search-lmi-capstone-test-bbewbwsli4uchb7r24zujwrqne.us-east-1.es.amazonaws.com'\n",
    "# auth = BotoAWSRequestsAuth(aws_host=host,\n",
    "#                            aws_region='us-east-1',\n",
    "#                            aws_service='es')\n",
    "# awsauth = AWS4Auth(YOUR_ACCESS_KEY, YOUR_SECRET_KEY, REGION, 'es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'dedbbb462bf60acdb6c63621c8bf117c', 'cluster_name': '846033058400:lmi-capstone-test', 'cluster_uuid': 'vhqZptiWQEq0BVgaN6qi8Q', 'version': {'number': '7.8.0', 'build_flavor': 'oss', 'build_type': 'tar', 'build_hash': 'unknown', 'build_date': '2020-10-15T22:09:28.519938Z', 'build_snapshot': False, 'lucene_version': '8.5.1', 'minimum_wire_compatibility_version': '6.8.0', 'minimum_index_compatibility_version': '6.0.0-beta1'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(host)\n",
    "\n",
    "# es = Elasticsearch(\n",
    "#     hosts=[{'host': host, 'port': 443}],\n",
    "#     use_ssl=True,\n",
    "#     verify_certs=True,\n",
    "#     connection_class=RequestsHttpConnection\n",
    "# )\n",
    "print(es.info())\n",
    "\n",
    "# es = Elasticsearch(\n",
    "#     hosts=[{'host': host, 'port': 443}],\n",
    "#     http_auth=auth,\n",
    "#     use_ssl=True,\n",
    "#     verify_certs=True,\n",
    "#     connection_class=RequestsHttpConnection\n",
    "# )\n",
    "# print(es.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Rule Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_url = \"https://mikeanders.org/data/CMS/CMS-2018-0101-0001/Rule/CMS-2018-0101-0001.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitRule_headers(rule_url):\n",
    "\n",
    "    alltxt = requests.get(rule_url).text.lower()#.encode('unicode_escape').decode() #encodes like raw strings\n",
    "    \n",
    "    #Isolate Section 2\n",
    "    initialsplit = alltxt.split(\"ii. provisions of the proposed regulations\") #split before section 2\n",
    "    sec2andon = initialsplit[1] #choose latter half\n",
    "    sec2list = sec2andon.split(\"iii. collection of information requirements\") #split before section 3\n",
    "    splitlist = sec2list[0] #choose first half\n",
    "    \n",
    "    rulechunks = {}\n",
    "    \n",
    "    startdict = {'a2':['2. proposals for modified participation options under 5-year agreement periods', '3. creating a basic track with glide path to performance-based risk'], \\\n",
    "     'a3':['3. creating a basic track with glide path to performance-based risk', '4. permitting annual participation elections'], \\\n",
    "    'a4b':['b. proposals for permitting election of differing levels of risk within the basic track\\'s glide path', 'c. proposals for permitting annual election of beneficiary assignment methodology'], \\\n",
    "    'a4c':['c. proposals for permitting annual election of beneficiary assignment methodology', '5. determining participation options based on medicare ffs revenue and prior participation '], \\\n",
    "    'a5b':['b. differentiating between low revenue acos and high revenue acos', 'c. determining participation options based on prior participation of aco legal entity and aco participants'], \\\n",
    "    'a5c':['c. determining participation options based on prior participation of aco legal entity and aco participants', 'd. monitoring for financial performance'], \\\n",
    "    'a5d': ['d. monitoring for financial performance', '6. requirements for aco participation in two-sided models'], \\\n",
    "    'a6b': ['b. election of msr/mlr by acos', 'c. aco repayment mechanisms'], \\\n",
    "    'a6c': ['c. aco repayment mechanisms', 'd. advance notice for and payment consequences of termination '], \\\n",
    "    'a6d2': ['(2) proposals for advance notice of voluntary termination', '(3) proposals for payment consequences of termination'], \\\n",
    "    'a6d3': ['(3) proposals for payment consequences of termination', '7. participation options for agreement periods beginning in 2019'], \\\n",
    "    'a7b': ['b. methodology for determining financial and quality performance for the 6-month performance years during 2019', 'c. applicability of program policies to acos participating in a 6-month performance year'], \\\n",
    "    'a7c': ['c. applicability of program policies to acos participating in a 6-month performance year', 'b. fee-for-service benefit enhancements'], \\\n",
    "    'b2a': ['a. shared savings program snf 3-day rule waiver', 'b. billing and payment for telehealth services'], \\\n",
    "    'b2b': ['b. billing and payment for telehealth services', 'c. providing tools to strengthen beneficiary engagement'], \\\n",
    "    'c2': ['2. beneficiary incentives', '3. empowering beneficiary choice'], \\\n",
    "    'c3a': ['3. empowering beneficiary choice', 'b. beneficiary opt-in based assignment methodology'], \\\n",
    "    'c3b': ['b. beneficiary opt-in based assignment methodology', 'd. benchmarking methodology refinements'],  \\\n",
    "    'd2': ['2. risk adjustment methodology for adjusting historical benchmark each performance year', '3. use of regional factors when establishing and resetting acos\\' benchmarks'], \\\n",
    "    'd3b': ['b. proposals to apply regional expenditures in determining the benchmark for an aco\\'s first agreement period', 'c. proposals for modifying the regional adjustment'], \\\n",
    "    'd3c': ['c. proposals for modifying the regional adjustment', 'd. proposals for modifying the methodology for calculating growth rates used in establishing, resetting, and updating the benchmark'], \\\n",
    "    'd3d': ['d. proposals for modifying the methodology for calculating growth rates used in establishing, resetting, and updating the benchmark', '4. technical changes to incorporate references to benchmark rebasing policies'], \\\n",
    "    'd4': ['4. technical changes to incorporate references to benchmark rebasing policies', 'e. updating program policies'], \\\n",
    "    'e2': ['2. revisions to policies on voluntary alignment', '3. revisions to the definition of primary care services used in beneficiary assignment'], \\\n",
    "    'e3': ['3. revisions to the definition of primary care services used in beneficiary assignment', '4. extreme and uncontrollable circumstances policies for the shared savings program'], \\\n",
    "    'e4': ['4. extreme and uncontrollable circumstances policies for the shared savings program', '5. program data and quality measures'], \\\n",
    "    'e5':['5. program data and quality measures', '6. promoting interoperability'], \\\n",
    "    'e6':['6. promoting interoperability', '7. coordination of pharmacy care for aco beneficiaries'], \\\n",
    "    'e7':['7. coordination of pharmacy care for aco beneficiaries', 'f. applicability of proposed policies to track 1+ model acos'], \\\n",
    "    'f2':['2. unavailability of application cycles for entry into the track 1+ model in 2019 and 2020', '3. applicability of proposed policies to track 1+ model acos through revised program regulations or revisions to track 1+ model participation agreements'], \\\n",
    "    'f3':['3. applicability of proposed policies to track 1+ model acos through revised program regulations or revisions to track 1+ model participation agreements', 'g. summary of proposed timing of applicability']}\n",
    "    \n",
    "    for key, value in startdict.items():    \n",
    "       splitlist = splitlist.split(value[0]) #split on start of desired section\n",
    "       split_further = splitlist[1].split(value[1]) #split again on start of undesired section\n",
    "       rulechunks[key] = {\"text\": value[0]+split_further[0]} #choose only first half to upload to dict\n",
    "       splitlist = splitlist[1] #choose second half to prepare for next split\n",
    "    \n",
    "    #print(rulechunks.keys())   \n",
    "    #print(rulechunks[\"f3\"])\n",
    "    \n",
    "    #lengths = [len(chunk) for chunk in rulechunks.values()]\n",
    "    #print(lengths) #characters\n",
    "    \n",
    "    return rulechunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitRule_chars(rule_url):\n",
    "    alltxt = requests.get(rule_url).text.lower()#.encode('unicode_escape').decode() #encodes like raw strings\n",
    "    \n",
    "    #Isolate Section 2\n",
    "    initialsplit = alltxt.split(\"ii. provisions of the proposed regulations\") #split before section 2\n",
    "    sec2andon = initialsplit[1] #choose latter half\n",
    "    sec2list = sec2andon.split(\"iii. collection of information requirements\") #split before section 3\n",
    "    splitlist = sec2list[0] #choose first half\n",
    "    \n",
    "    #chunk by num chars\n",
    "    chunklist = [(splitlist[i:i+8000]) for i in range(0, len(splitlist), 8000)]\n",
    "    \n",
    "    #make dict\n",
    "    rulechunks = {}\n",
    "    keys = range(len(chunklist))\n",
    "    for i in keys:\n",
    "        rulechunks[i] = {\"text\": chunklist[i]}\n",
    "\n",
    "    return rulechunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitRule_headchars(rule_url):\n",
    "    chunks = splitRule_headers(rule_url) #call first method\n",
    "    for key, value in chunks.items():\n",
    "        if len(value[\"text\"]) > 50000: #check to see if chunk is really long\n",
    "            smalldict = {}\n",
    "            chunklist = [value[\"text\"][i:i+25000] for i in range(0, len(value[\"text\"]), 25000)] #split chunk\n",
    "            keys = range(len(chunklist))\n",
    "            for i in keys:\n",
    "                smalldict[key+str(i)] = {\"text\": chunklist[i]} #add to sub-dictionary\n",
    "            chunks[key] = smalldict #add to big dictionary\n",
    "        else:\n",
    "            chunks[key] = {key+str(0): value} #add to big dictionary\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading Rule Splits to ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rulesplit_toES(rulechunks, es_index, idnum):\n",
    "    for key, value in rulechunks.items():\n",
    "            res = es.index(index=es_index, id=idnum, body={key:value}, doc_type='_doc')\n",
    "            idnum += 1\n",
    "            es.indices.refresh(index=es_index)\n",
    "    print(f\"Last id uploaded: {idnum-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruletoES_hybrid(rulechunks, es_index, idnum):\n",
    "    for key, value in rulechunks.items():\n",
    "        for small_key, small_value in value.items():\n",
    "            res = es.index(index=es_index, id=idnum, body={small_key:small_value})\n",
    "            idnum += 1\n",
    "            es.indices.refresh(index=es_index)\n",
    "    print(f\"Last id uploaded: {idnum-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesplit_test = splitRule_headers(rule_url)\n",
    "test_upload = rulesplit_toES(rulesplit_test, \"headers_new\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesplit_test2 = splitRule_chars(rule_url)\n",
    "test_upload2 = rulesplit_toES(rulesplit_test2, \"char_8000\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rulesplit_test3 = splitRule_headchars(rule_url)\n",
    "test_upload3 = ruletoES_hybrid(rulesplit_test3, \"hybrid_new\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ES Search\n",
    "def ES_search(index, querydict):\n",
    "    search = es.search(index=index, doc_type=\"_doc\", body={\"query\": querydict})\n",
    "    test_list = []\n",
    "    if search['hits']['hits'] != []:\n",
    "        for h in search['hits']['hits']:\n",
    "            key = list((h['_source'].keys()))\n",
    "            test_list.append({key[0]:h['_score']})\n",
    "    return test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = {\"simple_query_string\": {\"query\": \"urban\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a6c': 0.45770907},\n",
       " {'a4c': 0.45549875},\n",
       " {'b2b': 0.29446962},\n",
       " {'c2': 0.2554381}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_test_search = ES_search(\"headers_new\", test_query)\n",
    "headers_test_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'64': 0.29684716}, {'70': 0.29528618}, {'68': 0.29148874}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_test_search = ES_search(\"char_8000\", test_query)\n",
    "char_test_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'c20': 0.40307403},\n",
       " {'a4c15': 0.29141787},\n",
       " {'a6c7': 0.29115358},\n",
       " {'a6c8': 0.29011896},\n",
       " {'a4c16': 0.28976172},\n",
       " {'a4c17': 0.289463},\n",
       " {'a6c9': 0.28831965},\n",
       " {'b2b0': 0.1865641}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_test_search = ES_search(\"hybrid_new\", test_query)\n",
    "hybrid_test_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete an index:\n",
    "# es.indices.delete(index='index_name', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Comment Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_url = \"https://mikeanders.org/data/CMS/CMS-2018-0101-0001/Comments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_comments(comment_url):\n",
    "    comment_url = \"https://mikeanders.org/data/CMS/CMS-2018-0101-0001/Comments/\"\n",
    "    response = requests.get(comment_url)\n",
    "    soup = BeautifulSoup(response.text, 'html')\n",
    "    a_tags = soup.findAll(\"a\")\n",
    "    links = [tag[\"href\"] for tag in a_tags]\n",
    "    txt_links = [link for link in links if '.txt' in link]\n",
    "    comments = {}\n",
    "    for suffix in txt_links:\n",
    "        comments[suffix] = requests.get(comment_url+suffix).text.lower()\n",
    "        #print(f\"scraping comment {suffix}\")\n",
    "    print(f\"scraped {len(txt_links)} comments\")\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:177: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 194 of the file C:\\ProgramData\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  warnings.warn(self.NO_PARSER_SPECIFIED_WARNING % dict(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "request() got an unexpected keyword argument 'headers_test_searchers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-8364efa2e7bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomments2018\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mretrieve_comments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-117-cf185a1c87bf>\u001b[0m in \u001b[0;36mretrieve_comments\u001b[1;34m(comment_url)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcomments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msuffix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtxt_links\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mcomments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomment_url\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders_test_searchers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Connection'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m#print(f\"scraping comment {suffix}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"scraped {len(txt_links)} comments\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: request() got an unexpected keyword argument 'headers_test_searchers'"
     ]
    }
   ],
   "source": [
    "comments2018 = retrieve_comments(comment_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_lengths = {key: len(value) for key, value in comments2018.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_comment_lengths = dict(sorted(comment_lengths.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_short = {key: len(value) for key, value in comments2018.items() if \"attach\" in value and len(value) < 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comment001_query = {\"simple_query_string\": {\"query\": comments2018[\"CMS-2018-0101-0002.txt\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a4c': 144.72498},\n",
       " {'a6c': 142.13535},\n",
       " {'a5c': 110.61184},\n",
       " {'c3b': 106.4453},\n",
       " {'a3': 105.05455},\n",
       " {'a5b': 104.90532},\n",
       " {'a2': 103.80479},\n",
       " {'e4': 100.2969},\n",
       " {'a7c': 97.574455},\n",
       " {'a7b': 93.47521}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_search(\"headers_new\", test_comment001_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
